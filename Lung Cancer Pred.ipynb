{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rRM8yi8muHZI"
      },
      "outputs": [],
      "source": [
        "# Define paths to the training, validation, and test datasets\n",
        "train_folder = r'C:\\Users\\USER\\OneDrive\\Desktop\\final\\Lung-Cancer-Prediction-using-CNN-and-Transfer-Learning\\dataset\\train'\n",
        "test_folder = r'C:\\Users\\USER\\OneDrive\\Desktop\\final\\Lung-Cancer-Prediction-using-CNN-and-Transfer-Learning\\dataset\\test'\n",
        "validate_folder = r'C:\\Users\\USER\\OneDrive\\Desktop\\final\\Lung-Cancer-Prediction-using-CNN-and-Transfer-Learning\\dataset\\valid'\n",
        "# Define paths to the specific classes within the dataset\n",
        "normal_folder = '/normal'\n",
        "adenocarcinoma_folder = '/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib'\n",
        "large_cell_carcinoma_folder = '/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa'\n",
        "squamous_cell_carcinoma_folder = '/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfgV3VGxumfn",
        "outputId": "856c51e2-8677-469d-93b0-5e3469c9a959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries Imported\n",
            "Reading training images from: C:\\Users\\USER\\OneDrive\\Desktop\\final\\Lung-Cancer-Prediction-using-CNN-and-Transfer-Learning\\dataset\\train\n",
            "Reading validation images from: C:\\Users\\USER\\OneDrive\\Desktop\\final\\Lung-Cancer-Prediction-using-CNN-and-Transfer-Learning\\dataset\\valid\n",
            "Found 613 images belonging to 4 classes.\n",
            "Found 315 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout2D, Activation, Lambda, Flatten, LSTM\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "print(\"Libraries Imported\")\n",
        "\n",
        "# Set the image size for resizing\n",
        "IMAGE_SIZE = (350, 350)\n",
        "\n",
        "# Initialize the image data generators for training and testing\n",
        "print(\"Reading training images from:\", train_folder)\n",
        "print(\"Reading validation images from:\", validate_folder)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "# Define the batch size for training\n",
        "batch_size = 8\n",
        "\n",
        "\n",
        "# Create the training data generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_folder,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "\n",
        "# Create the validation data generator\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_folder,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=batch_size,\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0OaGHVpzuuzQ"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=best_model.hdf5",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m learning_rate_reduction = ReduceLROnPlateau(monitor=\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m5\u001b[39m, verbose=\u001b[32m2\u001b[39m, factor=\u001b[32m0.5\u001b[39m, min_lr=\u001b[32m0.000001\u001b[39m)\n\u001b[32m      5\u001b[39m early_stops = EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m, min_delta=\u001b[32m0\u001b[39m, patience=\u001b[32m6\u001b[39m, verbose=\u001b[32m2\u001b[39m, mode=\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m checkpointer = \u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbest_model.hdf5\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_weights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\OneDrive\\Desktop\\final\\.venv\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:184\u001b[39m, in \u001b[36mModelCheckpoint.__init__\u001b[39m\u001b[34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m save_weights_only:\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.filepath.endswith(\u001b[33m\"\u001b[39m\u001b[33m.weights.h5\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    185\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mWhen using `save_weights_only=True` in `ModelCheckpoint`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    186\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m, the filepath provided must end in `.weights.h5` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    187\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m(Keras weights format). Received: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    188\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfilepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.filepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    189\u001b[39m         )\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m    192\u001b[39m         \u001b[38;5;28mself\u001b[39m.filepath.endswith(ext) \u001b[38;5;28;01mfor\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    193\u001b[39m     ):\n",
            "\u001b[31mValueError\u001b[39m: When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=best_model.hdf5"
          ]
        }
      ],
      "source": [
        "# Set up callbacks for learning rate reduction, early stopping, and model checkpointing\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='loss', patience=5, verbose=2, factor=0.5, min_lr=0.000001)\n",
        "early_stops = EarlyStopping(monitor='loss', min_delta=0, patience=6, verbose=2, mode='auto')\n",
        "checkpointer = ModelCheckpoint(filepath='best_model.hdf5', verbose=2, save_best_only=True, save_weights_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emno-h9huzhT",
        "outputId": "93213a43-da41-4b96-b15c-f46cc35ffdc0"
      },
      "outputs": [],
      "source": [
        "# Define the number of output classes\n",
        "OUTPUT_SIZE = 4\n",
        "\n",
        "# Load a pre-trained model (Xception) without the top layers and freeze its weights\n",
        "pretrained_model = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n",
        "pretrained_model.trainable = False\n",
        "\n",
        "# Create a new model with the pre-trained base and additional layers for classification\n",
        "model = Sequential()\n",
        "model.add(pretrained_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(OUTPUT_SIZE, activation='softmax'))\n",
        "\n",
        "print(\"Pretrained model used:\")\n",
        "pretrained_model.summary()\n",
        "\n",
        "print(\"Final model created:\")\n",
        "model.summary()\n",
        "\n",
        "# Compile the model with an optimizer, loss function, and evaluation metric\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqBJ3ijCu5ug",
        "outputId": "b500bcbe-e8b9-4afa-8251-61162d55032d"
      },
      "outputs": [],
      "source": [
        "# Train the model with the training and validation data generators\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=25,\n",
        "    epochs=50,\n",
        "    callbacks=[learning_rate_reduction, early_stops, checkpointer],\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=20\n",
        ")\n",
        "\n",
        "print(\"Final training accuracy =\", history.history['accuracy'][-1])\n",
        "print(\"Final testing accuracy =\", history.history['val_accuracy'][-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j19VBeievBu3",
        "outputId": "0b6c01eb-0959-4f01-e403-92a40be776b5"
      },
      "outputs": [],
      "source": [
        "# Function to display training curves for loss and accuracy\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "    if subplot % 10 == 1:\n",
        "        plt.subplots(figsize=(10, 10), facecolor='#F0F0F0')\n",
        "        plt.tight_layout()\n",
        "    ax = plt.subplot(subplot)\n",
        "    ax.set_facecolor('#F8F8F8')\n",
        "    ax.plot(training)\n",
        "    ax.plot(validation)\n",
        "    ax.set_title('model ' + title)\n",
        "    ax.set_ylabel(title)\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.legend(['train', 'valid.'])\n",
        "\n",
        "# Display training curves for loss and accuracy\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 211)\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 212)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-84u6lCauRe"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/dataset/trained_lung_cancer_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "m6dlUjpwazCH",
        "outputId": "a63f1e24-dde0-45f7-8f4b-5dff63a85a54"
      },
      "outputs": [],
      "source": [
        "# Function to load and preprocess an image for prediction\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to load and preprocess the image\n",
        "def load_and_preprocess_image(img_path, target_size):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Rescale the image like the training images\n",
        "    return img_array\n",
        "\n",
        "# Load, preprocess, and predict the class of an image\n",
        "img_path = '/content/sq.png'\n",
        "img = load_and_preprocess_image(img_path, IMAGE_SIZE)\n",
        "\n",
        "# Make a prediction\n",
        "predictions = model.predict(img)\n",
        "predicted_class = np.argmax(predictions[0])\n",
        "\n",
        "# Map the predicted class to the class label\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "predicted_label = class_labels[predicted_class]\n",
        "\n",
        "# Print the predicted class\n",
        "print(f\"The image belongs to class: {predicted_label}\")\n",
        "\n",
        "# Display the image with the predicted class\n",
        "plt.imshow(image.load_img(img_path, target_size=IMAGE_SIZE))\n",
        "plt.title(f\"Predicted: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "JwYpmD_gbBeg",
        "outputId": "261687e2-7a94-4311-dd5a-8945928802a3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to load and preprocess the image\n",
        "def load_and_preprocess_image(img_path, target_size):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Rescale the image like the training images\n",
        "    return img_array\n",
        "\n",
        "# Load an image from your drive\n",
        "img_path = '/content/ad3.png'\n",
        "img = load_and_preprocess_image(img_path, IMAGE_SIZE)\n",
        "\n",
        "# Make a prediction\n",
        "predictions = model.predict(img)\n",
        "predicted_class = np.argmax(predictions[0])\n",
        "\n",
        "# Map the predicted class to the class label\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "predicted_label = class_labels[predicted_class]\n",
        "\n",
        "# Print the predicted class\n",
        "print(f\"The image belongs to class: {predicted_label}\")\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image.load_img(img_path, target_size=IMAGE_SIZE))\n",
        "plt.title(f\"Predicted: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "BqLwxHo5cOcW",
        "outputId": "86bfc946-ad65-405d-b01d-eb20963a12ee"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to load and preprocess the image\n",
        "def load_and_preprocess_image(img_path, target_size):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Rescale the image like the training images\n",
        "    return img_array\n",
        "\n",
        "# Load an image from your drive\n",
        "img_path = '/content/l3.png'\n",
        "img = load_and_preprocess_image(img_path, IMAGE_SIZE)\n",
        "\n",
        "# Make a prediction\n",
        "predictions = model.predict(img)\n",
        "predicted_class = np.argmax(predictions[0])\n",
        "\n",
        "# Map the predicted class to the class label\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "predicted_label = class_labels[predicted_class]\n",
        "\n",
        "# Print the predicted class\n",
        "print(f\"The image belongs to class: {predicted_label}\")\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image.load_img(img_path, target_size=IMAGE_SIZE))\n",
        "plt.title(f\"Predicted: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "nsqt-qsYcUzy",
        "outputId": "1c994f1c-7e14-45dd-961c-050ea68d019a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to load and preprocess the image\n",
        "def load_and_preprocess_image(img_path, target_size):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Rescale the image like the training images\n",
        "    return img_array\n",
        "\n",
        "# Load an image from your drive\n",
        "img_path = '/content/n8.jpg'\n",
        "img = load_and_preprocess_image(img_path, IMAGE_SIZE)\n",
        "\n",
        "# Make a prediction\n",
        "predictions = model.predict(img)\n",
        "predicted_class = np.argmax(predictions[0])\n",
        "\n",
        "# Map the predicted class to the class label\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "predicted_label = class_labels[predicted_class]\n",
        "\n",
        "# Print the predicted class\n",
        "print(f\"The image belongs to class: {predicted_label}\")\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image.load_img(img_path, target_size=IMAGE_SIZE))\n",
        "plt.title(f\"Predicted: {predicted_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11Ckj0SQca-h"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
